{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "sys.path.append(\"/users/ziyzhang/topology-research\")\n",
    "from topologies.DDF import DDFtopo\n",
    "from nexullance.MD_Nexullance_MP.MD_Nexullance_MP import MD_Nexullance_MP\n",
    "from nexullance.Nexullance_MP import Nexullance_MP\n",
    "sys.path.append(\"/users/ziyzhang/topology-research/nexullance/IT_boost/build\")\n",
    "from Nexullance_IT_cpp import MD_Nexullance_IT_interface\n",
    "import globals as gl\n",
    "import numpy as np\n",
    "import pickle\n",
    "import csv\n",
    "import time\n",
    "import tracemalloc\n",
    "import pandas as pd\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "Cap_remote = 10 #GBps\n",
    "Cap_local = 10 #GBps\n",
    "\n",
    "config = gl.ddf_configs[0]\n",
    "V = config[0]\n",
    "D = config[1]\n",
    "EPR = (D+1)//2\n",
    "_network = DDFtopo(V, D)\n",
    "arcs = _network.generate_graph_arcs()\n",
    "\n",
    "ASP, _ = _network.calculate_all_shortest_paths()\n",
    "ECMP_ASP = gl.ECMP(ASP)\n",
    "\n",
    "M_Rs = []\n",
    "M_R_names = []\n",
    "M_EPs = []\n",
    "max_local_link_loads = []\n",
    "\n",
    "# # # Define multiple traffic demand matrices:\n",
    "# # shifts\n",
    "for _shift in range(1, V*EPR):\n",
    "# for _shift in range(1, 5):\n",
    "    M_EP = gl.generate_shift_traffic_pattern(V, EPR, _shift)\n",
    "    # try to scale the traffic scaling factor to 10x saturation under ECMP_ASP\n",
    "    remote_link_flows, local_link_flows = _network.distribute_M_EPs_on_weighted_paths(ECMP_ASP, EPR, M_EP)\n",
    "    max_remote_link_load = np.max(remote_link_flows)/Cap_remote\n",
    "    max_local_link_load = np.max(local_link_flows)/Cap_local\n",
    "    traffic_scaling = 10.0/max(max_local_link_load, max_remote_link_load)\n",
    "    M_EP = traffic_scaling * M_EP\n",
    "    M_R = gl.convert_M_EPs_to_M_R(M_EP, V, EPR)\n",
    "    # ==============\n",
    "    # manage data\n",
    "    M_EPs.append(M_EP)\n",
    "    M_Rs.append(M_R)\n",
    "    max_local_link_loads.append(max_local_link_load)\n",
    "    M_R_names.append(f\"shift_{_shift}\")\n",
    "M_R_weights = [1/len(M_Rs) for _ in range(len(M_Rs))]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def do_MD_IT(alpha:float, beta:float) -> float:\n",
    "    # calculate Phi for MD_Nexullance_IT routing\n",
    "    md_nexu_it = MD_Nexullance_IT_interface(V, arcs, M_Rs, M_R_weights, False)\n",
    "    md_nexu_it.set_parameters(alpha, beta)\n",
    "    \n",
    "    tracemalloc.start()\n",
    "    start_time = time.time()\n",
    "    md_nexu_it.run()\n",
    "    end_time = time.time()\n",
    "    MD_peak_RAM = tracemalloc.get_traced_memory()[1]/1024/1024\n",
    "    MD_time = end_time-start_time\n",
    "    tracemalloc.stop()\n",
    "\n",
    "    return -1*md_nexu_it.get_weighted_max_link_load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "from bayes_opt import BayesianOptimization\n",
    "# Bounded region of parameter space\n",
    "pbounds = {'alpha': (0.1, 50.0), 'beta': (0.0, 50.0)}\n",
    "optimizer = BayesianOptimization(\n",
    "    f=do_MD_IT,\n",
    "    pbounds=pbounds,\n",
    "    random_state=1,\n",
    ")\n",
    "optimizer.probe(\n",
    "    params=[0.1, 7.0],\n",
    "    lazy=True,\n",
    ")\n",
    "optimizer.probe(\n",
    "    params=[20, 0.1],\n",
    "    lazy=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|   iter    |  target   |   alpha   |   beta    |\n",
      "-------------------------------------------------\n",
      "| \u001b[0m1        \u001b[0m | \u001b[0m-5.531   \u001b[0m | \u001b[0m0.1      \u001b[0m | \u001b[0m7.0      \u001b[0m |\n",
      "| \u001b[0m2        \u001b[0m | \u001b[0m-10.0    \u001b[0m | \u001b[0m20.0     \u001b[0m | \u001b[0m0.1      \u001b[0m |\n",
      "| \u001b[0m3        \u001b[0m | \u001b[0m-5.581   \u001b[0m | \u001b[0m20.91    \u001b[0m | \u001b[0m36.02    \u001b[0m |\n",
      "| \u001b[0m4        \u001b[0m | \u001b[0m-5.629   \u001b[0m | \u001b[0m0.1057   \u001b[0m | \u001b[0m15.12    \u001b[0m |\n",
      "| \u001b[0m5        \u001b[0m | \u001b[0m-5.619   \u001b[0m | \u001b[0m7.423    \u001b[0m | \u001b[0m4.617    \u001b[0m |\n",
      "| \u001b[0m6        \u001b[0m | \u001b[0m-5.609   \u001b[0m | \u001b[0m9.394    \u001b[0m | \u001b[0m17.28    \u001b[0m |\n",
      "| \u001b[0m7        \u001b[0m | \u001b[0m-5.568   \u001b[0m | \u001b[0m19.9     \u001b[0m | \u001b[0m26.94    \u001b[0m |\n",
      "| \u001b[0m8        \u001b[0m | \u001b[0m-5.636   \u001b[0m | \u001b[0m21.02    \u001b[0m | \u001b[0m34.26    \u001b[0m |\n",
      "| \u001b[0m9        \u001b[0m | \u001b[0m-5.619   \u001b[0m | \u001b[0m10.3     \u001b[0m | \u001b[0m43.91    \u001b[0m |\n",
      "| \u001b[0m10       \u001b[0m | \u001b[0m-5.635   \u001b[0m | \u001b[0m1.467    \u001b[0m | \u001b[0m33.52    \u001b[0m |\n",
      "| \u001b[0m11       \u001b[0m | \u001b[0m-5.636   \u001b[0m | \u001b[0m20.92    \u001b[0m | \u001b[0m27.93    \u001b[0m |\n",
      "| \u001b[95m12       \u001b[0m | \u001b[95m-5.526   \u001b[0m | \u001b[95m7.105    \u001b[0m | \u001b[95m9.905    \u001b[0m |\n",
      "| \u001b[0m13       \u001b[0m | \u001b[0m-5.64    \u001b[0m | \u001b[0m44.46    \u001b[0m | \u001b[0m50.0     \u001b[0m |\n",
      "| \u001b[0m14       \u001b[0m | \u001b[0m-5.569   \u001b[0m | \u001b[0m50.0     \u001b[0m | \u001b[0m28.99    \u001b[0m |\n",
      "| \u001b[0m15       \u001b[0m | \u001b[0m-5.638   \u001b[0m | \u001b[0m27.94    \u001b[0m | \u001b[0m50.0     \u001b[0m |\n",
      "| \u001b[0m16       \u001b[0m | \u001b[0m-5.611   \u001b[0m | \u001b[0m50.0     \u001b[0m | \u001b[0m10.33    \u001b[0m |\n"
     ]
    }
   ],
   "source": [
    "optimizer.maximize(\n",
    "    init_points=10,\n",
    "    n_iter=200,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'target': -2.8341131070711123,\n",
       " 'params': {'alpha': 4.6419767269134455, 'beta': 6.593203706205871}}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optimizer.max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gt",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
